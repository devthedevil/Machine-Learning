{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we just have only one output unit layer\n",
    "# we don't have any hidden layer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2) (4, 1)\n"
     ]
    }
   ],
   "source": [
    "# taking 'xor' gate\n",
    "x=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y=np.array([[0,1,1,0]]).T\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivativeSig(z):\n",
    "    return sig(z)*(1-sig(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no.of units in the input layer=2\n",
    "# no.of units in the hidden layer=2\n",
    "wh=2*np.random.random((2,2))-1 \n",
    "bh=2*np.random.random((1,2))-1\n",
    "wo=2*np.random.random((2,1))-1\n",
    "bo=2*np.random.random((1,1))-1\n",
    "lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # forward propagation without any hidden layer \n",
    "# # optimization in code\n",
    "# for iter in range(10000):\n",
    "#     output0=x\n",
    "#     output=sig(np.dot(output0,weights)+bias)\n",
    "\n",
    "#     first_term=output-y\n",
    "#     input_for_last_layer=np.dot(output0,weights)+bias\n",
    "#     second_term=derivativeSig(input_for_last_layer)\n",
    "#     first_two=first_term*second_term\n",
    "    \n",
    "    \n",
    "#     changes=np.dot(output0.T,first_two)\n",
    "#     weights-=lr*changes\n",
    "#     bias_changes=np.sum(first_two)\n",
    "#     bias-=lr*bias_changes\n",
    "# output=sig(np.dot(output0,weights)+bias)\n",
    "# weights,bias,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00552794],\n",
       "        [0.9947784 ],\n",
       "        [0.99366061],\n",
       "        [0.00494391]]), array([[-6.62838064, -6.65791917],\n",
       "        [ 6.81746534,  6.51183907]]), array([[ 3.32460428, -3.48860691]]), array([[-11.39377928],\n",
       "        [ 11.72916148]]), array([[5.45796949]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward propagation with a hidden layer \n",
    "for iter in range(100000):\n",
    "    output0=x #output of input layer is x\n",
    "    inputhidden=np.dot(output0,wh)+bh\n",
    "    outputhidden=sig(inputhidden)\n",
    "#     print(inputhidden.shape)\n",
    "    inputForOutputLayer=np.dot(outputhidden,wo)+bo\n",
    "    output=sig(inputForOutputLayer)\n",
    "\n",
    "    first_term_output_layer=output-y\n",
    "    second_term_output_layer=derivativeSig(inputForOutputLayer)\n",
    "    first_two_output_layer=first_term_output_layer*second_term_output_layer\n",
    "\n",
    "    first_term_hidden_layer=np.dot(first_two_output_layer,wo.T)\n",
    "    second_term_hidden_layer=derivativeSig(inputhidden)\n",
    "    first_two_hidden_layer=first_term_hidden_layer*second_term_hidden_layer\n",
    "\n",
    "    changes_ouput=np.dot(outputhidden.T,first_two_output_layer)\n",
    "    changes_ouput_bias=np.sum(first_two_output_layer,axis=0,keepdims=True)\n",
    "\n",
    "    changes_hidden=np.dot(output0.T,first_two_hidden_layer)\n",
    "    changes_hidden_bias=np.sum(first_two_hidden_layer,axis=0,keepdims=True)\n",
    "\n",
    "    wo-=lr*changes_ouput\n",
    "    bo-=lr*changes_ouput_bias\n",
    "    \n",
    "    wh-=lr*changes_hidden\n",
    "    bh-=lr*changes_hidden_bias\n",
    "    \n",
    "output0=x#output of input layer is x\n",
    "inputhidden=np.dot(output0,wh)+bh\n",
    "outputhidden=sig(inputhidden)\n",
    "inputForOutputLayer=np.dot(outputhidden,wo)+bo\n",
    "output=sig(inputForOutputLayer)\n",
    "output,wh,bh,wo,bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
